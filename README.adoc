= Hybrid Cloud
:experimental:

image:https://github.com/redhat-developer-demos/hybrid-cloud/workflows/backend/badge.svg[]
image:https://github.com/redhat-developer-demos/hybrid-cloud/workflows/frontend/badge.svg[]

== Download Sources

[source,bash,subs="+attributes"]
----
git clone -b knative https://github.com/redhat-developer-demos/hybrid-cloud #<.>
cd hybrid-cloud
export REPO_HOME="$PWD"
----

For rest of the document we will call $REPO_HOME; the folder where you have cloned the https://github.com/redhat-developer-demos/hybrid-cloud.

== Pre-requsites

An OpenShift 4 cluster with following components installed:

- OpenShift Pipelines
- OpenShift Serverless

Copy `$REPO_HOME/env/extravars.example` to `$REPO_HOME/env/extravars`, update it to match your setting. To provision OpenShift Pipelines and OpenShift Serverless run:

[source,bash,subs="+attributes"]
----
$REPO_HOME provision.sh <pass the kubeconfig file to use>
----
IMPORTANT: You need to run this command once against each Cluster with respective `$KUBECONFIG` file absolute path as argument.

=== CLI Tools

- https://github.com/tektoncd/cli[Tekton CLI]
- https://github.com/skupperproject/skupper/tree/0.3/cmd/skupper[Skupper CLI > 0.3.0]

== Deploy Services

=== Preparing Namespace

The demo will be deployed in the namespace `hybrid-demo`, the namespace need to be prepared with the following resources:

- The namespace itself need to be created
- Service Account with right roles needed for Skupper and Kn Service Deployment
- PeristentVolumeClaims(PVC) *hybrid-cloud-demo-sources* to hold the cloned resources
- ConfigMap called *maven-settings* to have the maven settings
- Soantype nexus for faster and quicker builds maven builds
- Finally the Tektoncd pipeline *hybrid-cloud-demo-deploy* to build and deploy the sources

Deploy these required resources by running:

[source,bash,attributes]
----
oc apply -k $REPO_HOME/k8s/
----

[IMPORTANT]
====
- Wait for nexus to run before deploying backend and front services
- Repeat the above command against all the OpenShift clusters where you are going to deploy the frontend and backend applications
====

Shift to the *hybrid-demo* project:

[source,bash,attributes]
----
oc project hybrd-demo
----

=== Deploy Skupper

To deploy Skupper Router and Controller, run the following command on each of your OpenShift Clusters:

[source,bash,attributes]
----
tkn pipeline start skupper-site-deploy \
   --serviceaccount skupper-site-controller \
   --param SITE_NAME=backend \
   --use-param-defaults \
   --showlog
----

Verify if Skupper is up and running before proceeeding to next section, you can verify by:

[source,bash,attributes]
----
skupper status
----

The command should show an output like:

[source,bash,attributes]
----

----

=== Backend 

All clusters where only *backend* service tier will be deployed, run:

[source,bash,attributes]
----
tkn pipeline start hybrid-cloud-demo-deploy \
   --serviceaccount kn-service-deployer-account \
   --param APP_NAME=backend \
   --use-param-defaults \
   --showlog  
----

=== Frontend

Finally create a token:

[source,bash,attributes]
----
skupper connection-token token.yaml

Connection token written to token.yaml
----

In *all the other clusters*, use the connection token created in the previous step:

[source, shell-session]
----
skupper init
skupper connect token.yaml
----

Everything is connected and ready to be used.
This has been the short-version to get started, continue reading if you want to learn how to build the Docker images, deply them , etc.

=== Skupper UI

If you run:

[source, shell-session]
----
kubectl get services 

NAME                    TYPE           CLUSTER-IP       EXTERNAL-IP                                                                  PORT(S)               AGE
hybrid-cloud-backend    ClusterIP      172.30.32.251    <none>                                                                       8080/TCP              40m
hybrid-cloud-frontend   LoadBalancer   172.30.25.65     add076df5798711eaad1a0241cddbab7-1371911574.eu-central-1.elb.amazonaws.com   8080:32647/TCP        39m
kubernetes              ClusterIP      172.30.0.1       <none>                                                                       443/TCP               71m
openshift               ExternalName   <none>           kubernetes.default.svc.cluster.local                                         <none>                70m
skupper-controller      ClusterIP      172.30.247.104   <none>                                                                       8080/TCP              34m
skupper-internal        ClusterIP      172.30.109.84    <none>                                                                       55671/TCP,45671/TCP   34m
skupper-messaging       ClusterIP      172.30.64.245    <none>                                                                       5671/TCP              34m
----

You'll notice that there is a `skupper-controller` service which is the entry point for the Skupper UI.
Expose this service so it is reachable from outside the cluster and you'll be able to access the Skupper UI.


