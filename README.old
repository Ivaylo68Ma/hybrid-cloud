= Hybrid Cloud
:experimental:
:namespace: hybrid-cloud-demo

image:https://github.com/redhat-developer-demos/hybrid-cloud/workflows/backend/badge.svg[]
image:https://github.com/redhat-developer-demos/hybrid-cloud/workflows/frontend/badge.svg[]

== Download Sources

[source,bash,subs="+attributes"]
----
git clone -b knative https://github.com/redhat-developer-demos/hybrid-cloud #<.>
cd hybrid-cloud
export REPO_HOME="$PWD"
----

For rest of the document we will call $REPO_HOME; the folder where you have cloned the https://github.com/redhat-developer-demos/hybrid-cloud.

== Pre-requsites

An OpenShift 4 cluster with following components installed:

- OpenShift Pipelines
- OpenShift Serverless

Copy `$REPO_HOME/env/extravars.example` to `$REPO_HOME/env/extravars`, update it to match your setting. To provision OpenShift Pipelines and OpenShift Serverless run:

[source,bash,subs="+attributes"]
----
$REPO_HOME provision.sh <pass the kubeconfig file to use>
----
IMPORTANT: You need to run this command once against each Cluster with respective `$KUBECONFIG` file absolute path as argument.

=== CLI Tools

- https://github.com/tektoncd/cli[Tekton CLI]
- https://github.com/skupperproject/skupper/tree/0.3/cmd/skupper[Skupper CLI > 0.3.0]

== Deploy Services

=== Preparing Namespace

The demo will be deployed in the namespace `{namespace}`, the namespace need to be prepared with the following resources:

- The namespace itself need to be created
- Service Account with right roles needed for Skupper and Kn Service Deployment
- PeristentVolumeClaims(PVC) *hybrid-cloud-demo-sources* to hold the cloned resources
- ConfigMap called *maven-settings* to have the maven settings
- Soantype nexus for faster and quicker builds maven builds
- Finally the Tektoncd pipeline 
    - *ksvc-deploy*:  to build and deploy the sources as Knative Service
    - *svc-deply*:  to build and deploy the sources as normal Kubernetes Service

Create the following essential resources before running the demo pipelines:

Create the Service Account and required Roles and RoleBindings:

[source,bash,attributes]
----
oc apply -k $REPO_HOME/k8s/rbac
----

Create Namespace, nexus, persistent volumes:

[source,bash,attributes]
----
oc apply -k $REPO_HOME/k8s/core
----

Wait for the nexus deployment to complete:

[source,bash,attributes]
----
oc rollout status --watch --timeout=180s deploy nexus
----

Create the Pipelines tasks:

[source,bash,attributes]
----
oc apply -k $REPO_HOME/k8s/pipelines
----

Deploy Skupper Site Controller

[source,bash,attributes]
----
oc apply -k $REPO_HOME/k8s/skupper
----

[IMPORTANT]
====
- Repeat the above command against all the OpenShift Clusters where you are going to deploy the frontend and backend applications
====

Shift to the *hybrid-cloud-demo* project:

[source,bash,subs="+attributes"]
----
oc project {namespace}
----

=== Update Cluster Tasks

[source,bash,attributes]
----
oc replace \
  -f https://raw.githubusercontent.com/tektoncd/catalog/master/task/buildah/0.1/buildah.yaml --dry-run=client -oyaml \
  | yq w - kind ClusterTask \
  | oc replace -f -
----


[source,bash,attributes]
----
oc replace \
  -f https://raw.githubusercontent.com/tektoncd/catalog/master/task/maven/0.1/maven.yaml --dry-run=client -oyaml \
  | yq w - kind ClusterTask \
  | oc replace -f -
----

[source,bash,attributes]
----
oc replace \
  -f https://raw.githubusercontent.com/tektoncd/catalog/master/task/kn/0.1/kn.yaml --dry-run=client -oyaml \
  | yq w - kind ClusterTask \
  | oc replace -f -
----

=== Deploy Skupper

To deploy Skupper Router and Controller, run the following command on each of your OpenShift Clusters:

[source,bash,attributes]
----
tkn pipeline start skupper-site-deploy \
   --serviceaccount skupper-site-controller \
   --param SITE_NAME=backend \
   --use-param-defaults \
   --showlog
----

Verify if Skupper is up and running before proceeeding to next section, you can verify by:

[source,bash,attributes]
----
skupper status
----


We are yet to create and connect the clouds(sites), hence you will see an output like:

[source,text]
----
Skupper is enabled for namespace '"hybrid-cloud-demo" in interior mode'. It is not connected to any other sites. It has no exposed services.
----

=== Backend 

All clusters where only *backend* service tier will be deployed, run:

==== Knative

[source,bash,subs="macros+,+attributes"]
----
tkn pipeline start ksvc-deploy \
   --serviceaccount hybrid-cloud-demo-sa \
   --param APP_NAME=hybrid-cloud-backend \
   --param SERVICE_TIER=backend \
   --workspace=name=source,claimName=hybrid-cloud-demo-sources \
   --workspace=name=maven-settings,config=maven-settings \
   --use-param-defaults \
   --dry-run  
----

Setting *KN_MAX_SCALE* for the cluster to be 1, so it can distribute the load across clouds.

The successfull deployment creates a Skupper HTTP Proxy for the backened called *hybrid-cloud-backend-skupper*. The Frontends should the service *hybrid-cloud-backend-skupper* for connecting with backend API.

==== Vanilla Kubernetes Application

[source,bash,subs="macros+,+attributes"]
----
tkn pipeline start svc-deploy \
   --serviceaccount hybrid-cloud-demo-sa \
   --param APP_NAME=hybrid-cloud-backend \
   --param SERVICE_TIER=backend \
   --workspace=name=source,claimName=hybrid-cloud-demo-sources \
   --workspace=name=maven-settings,config=maven-settings \
   --use-param-defaults \
   --dry-run 
----

NOTE: First deployment will take some time as Maven artfiacts need to be downloaded and cached in nexus

=== Frontend

On the cluster where only *frontend* service tier will be deployed, run:

[source,bash,subs="+attributes"]
----
tkn pipeline start svc-deploy \
   --serviceaccount hybrid-cloud-demo-sa \
   --param APP_NAME=hybrid-cloud-frontend \
   --param SERVICE_TIER=frontend \
   --param BACKEND_SERVICE_URL='http://hybrid-cloud-backend-skupper:8080' \
   --workspace=name=source,claimName=hybrid-cloud-demo-sources \
   --workspace=name=maven-settings,config=maven-settings \
   --use-param-defaults \
   --dry-run 
----

[source,bash,subs="+attributes"]
----
oc get secret -n {namespace} site-token -o yaml > token.yaml
----

In all clusters than *frontend*, use the connection token created in the previous step and connect the services to create the Virtual Application Network(VAN)

[source,bash,subs="+attributes"]
----
oc create -n {namespace} -f token.yaml
----

Everything is connected and ready to be used.

=== Knative Burst

Open three terminals (one for each cloud ) to watch:

[source,bash,subs="+attributes"]
----
watch oc get pods -l=serving.knative.dev/configuration=hybrid-cloud-backend
----

Since all the backen concurrency is set to `1`, trying the following load test will distrbute the Knative load across all the clouds where the backend is deployed:

[source,bash,subs="+attributes"]
----
hey -z 10s -c 50 \
  -m POST \
  -H "Content-Type: application/json" \
  -d '{"maximumNumber": 10000,"sleepInSeconds": 3, "memoryLoadInMB": 100 }' \
  https://hybrid-cloud-frontend-hybrid-cloud-demo.apps.gcp.kameshs.dev/api/prime
----

With that above command you see the distribution of load across all the clouds once the *MAX_SCALE* value exceeds in the closest cloud(site).



=== Skupper UI

#TODO#


